{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faa82ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "learn_rate = 0.005  # 学习率\n",
    "# 数据预处理：将图片转为Tensor且归一化到[0,1]\n",
    "transform = transforms.ToTensor()\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图片转换为Tensor    0~255\n",
    "    transforms.Lambda(lambda x:x - 0.5)  # 将像素值从[0, 1]转换到[-0.5, 0.5]\n",
    "])\n",
    "# 下载训练集，若已下载则直接读取\n",
    "train_dataset = datasets.MNIST(root='./data',  # 存放数据的目录\n",
    "                               train=True,     # 加载训练集(True) or 测试集(False)\n",
    "                               transform=transform,  # 上面定义的预处理\n",
    "                               download=True)  # 没数据时自动下载\n",
    "\n",
    "# 同理，加载测试集\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                              train=False,\n",
    "                              transform=transform,\n",
    "                              download=True)\n",
    "\n",
    "print(len(train_dataset))  # 60000\n",
    "print(len(test_dataset))   # 10000\n",
    "\n",
    "train_dataset = Subset(train_dataset, range(1000))  # pick 前1000个样本\n",
    "# datas = [subset[i][0].numpy() for i in range(len(subset))]  # datas是list，存所有图片\n",
    "# labels = [subset[i][1] for i in range(len(subset))]         # labels是list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db64ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "[Step 100] Past 100 steps: Average Loss 2.269 | Accuracy: 21%\n",
      "[Step 200] Past 100 steps: Average Loss 2.080 | Accuracy: 36%\n",
      "[Step 300] Past 100 steps: Average Loss 1.577 | Accuracy: 59%\n",
      "[Step 400] Past 100 steps: Average Loss 1.056 | Accuracy: 65%\n",
      "[Step 500] Past 100 steps: Average Loss 0.972 | Accuracy: 68%\n",
      "[Step 600] Past 100 steps: Average Loss 0.880 | Accuracy: 71%\n",
      "[Step 700] Past 100 steps: Average Loss 0.592 | Accuracy: 83%\n",
      "[Step 800] Past 100 steps: Average Loss 0.692 | Accuracy: 83%\n",
      "[Step 900] Past 100 steps: Average Loss 0.726 | Accuracy: 76%\n",
      "[Step 1000] Past 100 steps: Average Loss 0.761 | Accuracy: 75%\n",
      "Epoch 2\n",
      "[Step 100] Past 100 steps: Average Loss 0.529 | Accuracy: 86%\n",
      "[Step 200] Past 100 steps: Average Loss 0.474 | Accuracy: 88%\n",
      "[Step 300] Past 100 steps: Average Loss 0.619 | Accuracy: 76%\n",
      "[Step 400] Past 100 steps: Average Loss 0.549 | Accuracy: 84%\n",
      "[Step 500] Past 100 steps: Average Loss 0.522 | Accuracy: 85%\n",
      "[Step 600] Past 100 steps: Average Loss 0.590 | Accuracy: 84%\n",
      "[Step 700] Past 100 steps: Average Loss 0.462 | Accuracy: 85%\n",
      "[Step 800] Past 100 steps: Average Loss 0.388 | Accuracy: 89%\n",
      "[Step 900] Past 100 steps: Average Loss 0.445 | Accuracy: 85%\n",
      "[Step 1000] Past 100 steps: Average Loss 0.532 | Accuracy: 87%\n",
      "Epoch 3\n",
      "[Step 100] Past 100 steps: Average Loss 0.476 | Accuracy: 84%\n",
      "[Step 200] Past 100 steps: Average Loss 0.483 | Accuracy: 82%\n",
      "[Step 300] Past 100 steps: Average Loss 0.382 | Accuracy: 88%\n",
      "[Step 400] Past 100 steps: Average Loss 0.432 | Accuracy: 88%\n",
      "[Step 500] Past 100 steps: Average Loss 0.431 | Accuracy: 87%\n",
      "[Step 600] Past 100 steps: Average Loss 0.355 | Accuracy: 91%\n",
      "[Step 700] Past 100 steps: Average Loss 0.528 | Accuracy: 90%\n",
      "[Step 800] Past 100 steps: Average Loss 0.266 | Accuracy: 93%\n",
      "[Step 900] Past 100 steps: Average Loss 0.335 | Accuracy: 90%\n",
      "[Step 1000] Past 100 steps: Average Loss 0.393 | Accuracy: 91%\n",
      "Training complete.\n",
      "Test Loss: 0.498\n",
      "Test Accuracy: 83.62%\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "#28x28x1→26x26x8\n",
    "\n",
    "class Conv3x3:\n",
    "    def __init__(self, num_filters):\n",
    "        self.num_filters = num_filters#记录一下卷积核层数\n",
    "        self.filters = torch.randn(num_filters, 3, 3) / 9#初始化卷积核\n",
    "    def iterate_patchs(self, input):\n",
    "        h, w = input.shape#获取图像的高和宽\n",
    "        for i in range(h - 2):\n",
    "            for j in range(w - 2):\n",
    "                patch = input[i:i + 3, j:j + 3]#每次取一个3x3的patch\n",
    "                # print(patch.shape)\n",
    "                yield patch, i, j\n",
    "    def forward(self, input):\n",
    "        self.last_input = input\n",
    "        h, w = input.shape\n",
    "        output = torch.zeros((h - 2, w - 2, self.num_filters))#output是少了（3-1）的八层\n",
    "        for patch, i, j in self.iterate_patchs(input):#遍历每个patch\n",
    "            output[i, j] = torch.sum(patch * self.filters, dim = (1, 2))#对每个patch和卷积核进行卷积操作\n",
    "        return output\n",
    "    def backprop(self, d_L_d_out):\n",
    "        d_L_d_filters = torch.zeros(self.filters.shape)#初始化梯度\n",
    "        # print(d_L_d_filters.shape, d_L_d_out.shape, self.last_input.shape)\n",
    "        for patch, i, j in self.iterate_patchs(self.last_input):\n",
    "            for f in range(self.num_filters):\n",
    "                d_L_d_filters[f] += patch * d_L_d_out[i, j, f]\n",
    "\n",
    "        self.filters -= learn_rate * d_L_d_filters#更新卷积核\n",
    "\n",
    "\n",
    "class MaxPool2:\n",
    "    def iterate_patchs(self, input):\n",
    "        h, w, _ = input.shape\n",
    "        new_h = h // 2\n",
    "        new_w = w // 2\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                patch = input[i * 2:i * 2 + 2, j * 2:j * 2 + 2]\n",
    "                yield patch, i, j\n",
    "    def forward(self, input):\n",
    "        self.last_input = input#记录输入\n",
    "        h, w, d = input.shape\n",
    "        output = torch.zeros((h // 2, w // 2, d))#output是大小折半的八层\n",
    "        for patch, i, j in self.iterate_patchs(input):\n",
    "            output[i, j] = torch.amax(patch, dim = (0, 1))\n",
    "        return output#13x13x8的输出\n",
    "    def backprop(self, d_L_d_out):\n",
    "        d_L_d_input = torch.zeros(self.last_input.shape)#初始化梯度\n",
    "        # print(d_L_d_out.shape, self.last_input.shape)\n",
    "        for patch, i, j in self.iterate_patchs(self.last_input):\n",
    "            # 找到最大值的索引\n",
    "            h, w, d = patch.shape\n",
    "            amax = torch.amax(patch, dim=(0, 1))\n",
    "            # 将梯度传递到最大值的位置\n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                    for d2 in range(d):\n",
    "                        if patch[i2, j2, d2] == amax[d2]:#如果patch中的值等于最大值\n",
    "                            d_L_d_input[i * 2 + i2, j * 2 + j2, d2] += d_L_d_out[i, j, d2]\n",
    "        return d_L_d_input\n",
    "\n",
    "class Softmax:\n",
    "    def __init__(self, input_size, nodes):#输入有多大来创建W和b\n",
    "        self.weights = torch.randn(input_size, nodes) / input_size#初始化W\n",
    "        self.bias = torch.zeros(nodes)\n",
    "    def forward(self, input):\n",
    "        self.last_input_shape = input.shape#记录输入的形状\n",
    "        input = input.flatten()#将输入展平,这里的输入是13x13x8的\n",
    "        self.last_input = input#记录输入\n",
    "        # print(input.shape, self.weights.shape, self.bias.shape)\n",
    "        totals = torch.matmul(input, self.weights) + self.bias#计算总和\n",
    "        self.last_totals = totals#记录总和\n",
    "        exp = torch.exp(totals)#计算指数,10维向量\n",
    "        return exp / torch.sum(exp)\n",
    "    def backprop(self, d_L_d_out):\n",
    "        for i, gradient in enumerate(d_L_d_out):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "            # 计算梯度\n",
    "            t_exp = torch.exp(self.last_totals)#计算指数\n",
    "            S = torch.sum(t_exp)#计算总和\n",
    "            # print('t_exp:', t_exp)\n",
    "            # print('t_exp.shape:', t_exp.shape)\n",
    "            # print('i:', i)\n",
    "            d_out_d_t = -t_exp[i] * t_exp / (S ** 2)#梯度\n",
    "            d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n",
    "\n",
    "            d_t_d_w = self.last_input\n",
    "            d_t_d_b = 1\n",
    "            d_t_d_inputs = self.weights\n",
    "\n",
    "            d_L_d_t = gradient * d_out_d_t#损失函数对总和的梯度\n",
    "            # print(type(d_t_d_w))\n",
    "            d_t_d_w = d_t_d_w.unsqueeze(1)  # 确保d_t_d_w是二维的\n",
    "            d_L_d_t = d_L_d_t.unsqueeze(0)  # 确保d_L_d_t是二维的\n",
    "            # print(type(d_t_d_w), type(d_L_d_t))\n",
    "            # print(d_t_d_w.shape, d_L_d_t.shape)\n",
    "            # print(d_t_d_w.numel(), d_L_d_t.numel())\n",
    "            d_L_d_w = torch.matmul(d_t_d_w, d_L_d_t)\n",
    "            d_L_d_b = d_L_d_t * d_t_d_b\n",
    "            d_L_d_inputs = torch.matmul(d_t_d_inputs, d_L_d_t.T)\n",
    "            # print(d_L_d_w, d_L_d_b, d_L_d_inputs.shape)\n",
    "            self.weights -= learn_rate * d_L_d_w\n",
    "            self.bias -= learn_rate * d_L_d_b.squeeze()\n",
    "            # print(self.weights, self.bias)\n",
    "            # print(self.last_input_shape)#1352\n",
    "            return d_L_d_inputs.reshape(13, 13, 8)\n",
    "\n",
    "\n",
    "\n",
    "#训练部分，包括loss损失函数\n",
    "conv = Conv3x3(8)\n",
    "pool = MaxPool2()\n",
    "softmax = Softmax(13 * 13 * 8, 10)\n",
    "\n",
    "def forward(input, label):#input是一个28x28的图像，label是对应的标签\n",
    "    out = conv.forward(input)\n",
    "    out = pool.forward(out)\n",
    "    out = softmax.forward(out)\n",
    "    loss = -torch.log(out[label])\n",
    "    acc = 1 if torch.argmax(out) == label else 0\n",
    "    return out, loss, acc\n",
    "\n",
    "\n",
    "def train(im, label):\n",
    "    out, loss, acc = forward(im, label)\n",
    "    gradient = torch.zeros(10)\n",
    "    gradient[label] = -1 / out[label]\n",
    "\n",
    "    gradient = softmax.backprop(gradient)\n",
    "    gradient = pool.backprop(gradient)\n",
    "    gradient = conv.backprop(gradient)\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "for epoch in range(3):  # 训练3个epoch\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    # permutation = torch.randperm(len(train_dataset))  # 打乱数据集\n",
    "    # train_dataset = train_dataset[permutation]  # 打乱后的训练集\n",
    "    permutation = torch.randperm(len(train_dataset))\n",
    "    train_dataset = Subset(train_dataset, permutation.tolist())  # 变成新的Dataset\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    # 遍历训练集\n",
    "    for i, (image, label) in enumerate(train_dataset):\n",
    "        image = image.squeeze(0)  # 添加batch维度\n",
    "        l, acc = train(image, label)\n",
    "        loss += l.item()  # 累加损失\n",
    "        num_correct += acc  # 累加正确预测的数量\n",
    "        if i % 100 == 99:  # 每1000个样本输出一次\n",
    "            # print(f\"Step {i+1}, Loss: {loss / (i + 1)}, Accuracy: {num_correct / (i + 1)}\")\n",
    "            print(\"[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%\" % (i + 1, loss/100, num_correct))\n",
    "            loss = 0  # 重置损失\n",
    "            num_correct = 0  # 重置正确预测计数\n",
    "print(\"Training complete.\")\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "for (image, label) in test_dataset:\n",
    "    _, l, acc = forward(image.squeeze(0), label)\n",
    "    loss += l.item()  # 累加损失\n",
    "    num_correct += acc  # 累加正确预测的数量\n",
    "\n",
    "num_tests = len(test_dataset)\n",
    "print(\"Test Loss: %.3f\" % (loss / num_tests))\n",
    "print(\"Test Accuracy: %.2f%%\" % (num_correct / num_tests * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "635dbafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "print(a.shape)\n",
    "a = a.unsqueeze(0)  # 移除维度为1的维度\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da081fbc",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a654ee59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape)  # 输出第一个样本的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe4da2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0\n",
      "0   1\n",
      "0   2\n",
      "0   3\n",
      "1   0\n",
      "1   1\n",
      "1   2\n",
      "1   3\n",
      "2   0\n",
      "2   1\n",
      "2   2\n",
      "2   3\n",
      "3   0\n",
      "3   1\n",
      "3   2\n",
      "3   3\n"
     ]
    }
   ],
   "source": [
    "def AAA(a):\n",
    "    for i in range(a):\n",
    "        for j in range(a):\n",
    "            yield i, j\n",
    "\n",
    "for i, j in AAA(4):\n",
    "    print(i,\" \",j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
